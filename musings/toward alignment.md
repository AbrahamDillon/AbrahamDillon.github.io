# Toward Alignment
By Abe Dillon

# Abstract 
In this article, I propose a path to achieve alignment with living systems based on a rigorous formalization of life as an information-theoretic phenomenon.

I argue that the problem of aligning the goal of one agent to another extends well beyond the narrow scope of artificial agents and that misalignment among humans, human collectives (states, corporations, economic systems, etc.), and other organisms poses an existential threat to human society of roughly the same magnitude (severe) and urgency (very) regardless of any further development of artificial intelligence. I claim that misalignment among humans stems largely from variations in the objective function of each human which imperfectly approximates some ideal objective and that achieving alignment requires deriving said ideal objective. In order to derive such an objective (what a human ought to ought to do) one must find a way to circumvent Hume's law. I reason that abiogenesis must be what I call a "trans-Humean" process (pardon the tongue-in-cheek naming) since, by definition, it gives rise to goal-driven agents (organisms) where before there were none. I then propose that the goal of an organism approximates an ideal goal which can be derived from a formalization of the phenomenon of life.

For instance, one can roughly outline the objective function of a human as some reconciliation of the needs of an individual (e.g. Mazlo's hierarchy) against some morals (e.g. ideals based on the foundations of morality as described in the field of moral psychology). It's clear that base needs like securing nutrients and procreating serve a general purpose of continuing life. Morality, on the other hand; largely serves to promote cooperation which is a key survival strategy. One which biology has converged upon numerous times. There are mechanisms in most multi-cellular organisms, for instance; that act as a set of "morals" that constrain the each cell's behaviors for the sake of cooperation. When those mechanisms break down, an individual cell can act as though it just became infatuated with Ayn Rand's "philosophy" of "rational egoism", believeing that behavior which serves the cell's own self-interest is paramount over the needs of the collective. The cell will consume resources without constraint, proliferate without constraint, and generally indulge in toxic, selfish behavior. We call such cells "cancer".

# Background
## Motivation
The alignment problem is typically framed in the context of artificial intelligence: What if we set a machine to work brutally optimizing solutions to satisfy a goal that's poorly aligned with the good of humanity? In that context, much has already been written about the potential danger posed as machines become increasingly powerfull at optimization. However, I believe we should consider a more general definition of the problem which omits the "artificial" qualifier because it distracts from the more general nature of the problem. We can see that humans can be unaligned with humans, or larger systems like economies can be unaligned with human interests, and octopuses can be unaligned with extra terrestrials.

The general alignment problem is not just about the hypothetical threat posed by artificial intelligence. It's at the heart of every ideological conflict and it's the reason Global Capitalism externalizes the cost of human suffering and ecological degredation. Whenever perverse incentives yield unwanted behavior in an intelligent system, whether it be addiction in the human brain or regulatory capture in a government, a poorly defined and/or implemented goal is likely to blame resulting in misalgnment.

## Definition
What the problem is. 

## Criteria 
Provide "tests" for acessing success

# Proposal

# Discussion
## Results
Evaluate the proposal against the defined criteria
## Insights
## Open Questions

# Conclusion 
